services:
  invokeai:
    image: "ghcr.io/invoke-ai/invokeai:latest"
    restart: unless-stopped
    build:
      context: ..
      dockerfile: docker/Dockerfile

    env_file:
      - .env
    networks:
      - traefik
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.invokeai-cuda.rule=Host(`invoke.docker.localhost`)"
      - "traefik.http.routers.invokeai-cuda.entrypoints=websecure"
      - "traefik.http.services.invokeai-cuda.loadbalancer.server.port=9090"
      - "traefik.http.routers.invokeai-cuda.tls=true"
    # variables without a default will automatically inherit from the host environment
    ports:
      - 9090:9090
    environment:
      # if set, CONTAINER_INVOKEAI_ROOT will override the Invoke runtime directory location *inside* the container
      - INVOKEAI_ROOT=${CONTAINER_INVOKEAI_ROOT:-/invokeai}
      - HF_HOME
    volumes:
      - type: bind
        source: ${HOST_INVOKEAI_ROOT:-${INVOKEAI_ROOT:-~/invokeai}}
        target: ${CONTAINER_INVOKEAI_ROOT:-/invokeai}
        bind:
          create_host_path: true
      - ${HF_HOME:-~/.cache/huggingface}:${HF_HOME:-/invokeai/.cache/huggingface}
    tty: true
    stdin_open: true
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
networks:
  traefik:
    external: true
